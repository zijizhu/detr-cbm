{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_clip = torch.load('outputs/detr_clip_train0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = detr_clip[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detr_f', 'clip_f', 'outputs', 'targets']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sample.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 256]),\n",
       " torch.Size([1024]),\n",
       " ['pred_logits', 'pred_boxes'],\n",
       " ['boxes', 'labels', 'image_id', 'area', 'iscrowd', 'orig_size', 'size'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['detr_f'].size(), sample['clip_f'].size(), list(sample['outputs'].keys()), list(sample['targets'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetrClipFuser(nn.Module):\n",
    "    def __init__(self, d_detr, d_clip, text_encoded) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_clip\n",
    "        self.linear_projection = nn.Linear(d_detr, d_clip)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=self.d_model, nhead=12)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=6)\n",
    "    \n",
    "    def forward(self, clip_img_feature, detr_proposals):\n",
    "        detr_projected = self.linear_projection(detr_proposals)\n",
    "        out = self.decoder(tgt=detr_projected, memory=clip_img_feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logichoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
