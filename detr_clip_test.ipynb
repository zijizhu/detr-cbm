{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.21s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from cocoeval import CocoEvaluator\n",
    "from detr.models.detr import PostProcess\n",
    "from detr.models.matcher import HungarianMatcher\n",
    "\n",
    "clip_model, clip_preprocess = clip.load('RN50', device='cpu')\n",
    "coco_val = COCO(annotation_file='coco/annotations/instances_val2017.json')\n",
    "\n",
    "model = nn.Linear(256, 1024)\n",
    "model.load_state_dict(torch.load('checkpoints/detr_r50_to_clip_r50_linear_epoch4.pth')['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = torch.load('detr/outputs/detr_outputs_val.pth')\n",
    "\n",
    "coco_evaluator = CocoEvaluator(coco_val, ('bbox',))\n",
    "\n",
    "matcher = HungarianMatcher(cost_class=1, cost_bbox=5, cost_giou=2)\n",
    "postprocess = PostProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['a ' + coco_val.cats[i]['name'] if i in coco_val.cats else 'unknown' for i in range(91)] + ['unknown']\n",
    "idx2cocoid = [k for k in coco_val.cats]\n",
    "texts_tokenized = clip.tokenize(texts)\n",
    "texts_encoded = clip_model.encode_text(texts_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:17<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=2.26s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.624\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.203\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.609\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.531\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.628\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.803\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(val):\n",
    "    target_sizes = torch.stack([t['orig_size'] for t in batch['targets']], dim=0)\n",
    "    batch_matched_idxs = matcher(batch['outputs'], batch['targets'])\n",
    "    batch_results = postprocess(batch['outputs'], target_sizes)\n",
    "\n",
    "    res = {target['image_id'].item(): output for target, output in zip(batch['targets'], batch_results)}\n",
    "    coco_evaluator.update(res)\n",
    "\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "coco_evaluator.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:13<00:00, 47.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=2.43s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.190\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.270\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.199\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.272\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.133\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.452\n"
     ]
    }
   ],
   "source": [
    "coco_evaluator = CocoEvaluator(coco_val, ('bbox',))\n",
    "for batch in tqdm(val):\n",
    "    target_sizes = torch.stack([t['orig_size'] for t in batch['targets']], dim=0)\n",
    "    batch_matched_idxs = matcher(batch['outputs'], batch['targets'])\n",
    "    batch_results = postprocess(batch['outputs'], target_sizes)\n",
    "\n",
    "    res = {target['image_id'].item(): output for target, output in zip(batch['targets'], batch_results)}\n",
    "\n",
    "    for i, results in enumerate(batch_results):\n",
    "        features, img_id = batch['h'][i], batch['targets'][i]['image_id'].item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features) @ texts_encoded.T\n",
    "            clip_probs = F.softmax(logits, dim=-1)\n",
    "            values, labels = clip_probs.max(dim=-1)\n",
    "        \n",
    "        res[img_id]['labels'] = labels\n",
    "\n",
    "    coco_evaluator.update(res)\n",
    "\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "coco_evaluator.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logichoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
